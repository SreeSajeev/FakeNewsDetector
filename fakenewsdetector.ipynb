{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SreeSajeev/FakeNewsDetector/blob/main/fakenewsdetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89d6d9b4",
      "metadata": {
        "id": "89d6d9b4"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\data science\\python_project\\Fake-News-Detector\\FakeNewsDetector\\news.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f95a06",
      "metadata": {
        "id": "73f95a06",
        "outputId": "62a80b07-a1fc-47b4-e1d2-9e3f44caaac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Unnamed: 0                                              title  \\\n",
            "0        8476                       You Can Smell Hillary’s Fear   \n",
            "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
            "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
            "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
            "4         875   The Battle of New York: Why This Primary Matters   \n",
            "\n",
            "                                                text label  \n",
            "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
            "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
            "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
            "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
            "4  It's primary day in New York and front-runners...  REAL  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6335 entries, 0 to 6334\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  6335 non-null   int64 \n",
            " 1   title       6335 non-null   object\n",
            " 2   text        6335 non-null   object\n",
            " 3   label       6335 non-null   object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 198.1+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(df.head())\n",
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ed84932",
      "metadata": {
        "id": "6ed84932",
        "outputId": "7eb48ed9-7cbb-4781-a646-fb09492a2b61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "763f094a",
      "metadata": {
        "id": "763f094a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Drop Unnamed column if present\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop(columns=['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "973667c4",
      "metadata": {
        "id": "973667c4"
      },
      "outputs": [],
      "source": [
        "# Merge title + text into full_text\n",
        "df['full_text'] = df['title'].fillna('') + ' ' + df['text'].fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60d2190f",
      "metadata": {
        "id": "60d2190f",
        "outputId": "67687aad-d161-41b3-83f9-2b646309db7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0                       You Can Smell Hillary’s Fear   \n",
            "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
            "2        Kerry to go to Paris in gesture of sympathy   \n",
            "3  Bernie supporters on Twitter erupt in anger ag...   \n",
            "4   The Battle of New York: Why This Primary Matters   \n",
            "\n",
            "                                                text label  \n",
            "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
            "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
            "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
            "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
            "4  It's primary day in New York and front-runners...  REAL  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Preview\n",
        "print(df[['title', 'text', 'label']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44a2ac74",
      "metadata": {
        "id": "44a2ac74"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation and non-alphabetic characters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['full_text'].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b5a99d",
      "metadata": {
        "id": "e0b5a99d"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "df['clean_text'] = df['clean_text'].apply(remove_stopwords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b481773",
      "metadata": {
        "id": "2b481773"
      },
      "outputs": [],
      "source": [
        "# If not already binary: 'FAKE' → 0, 'REAL' → 1\n",
        "df['label'] = df['label'].map({'FAKE': 0, 'REAL': 1})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb991ca",
      "metadata": {
        "id": "dbb991ca",
        "outputId": "6db72316-d855-432c-9e36-6a83a660b4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          clean_text  label\n",
            "0  smell hillarys fear daniel greenfield shillman...      0\n",
            "1  watch exact moment paul ryan committed politic...      0\n",
            "2  kerry go paris gesture sympathy us secretary s...      1\n",
            "3  bernie supporters twitter erupt anger dnc trie...      0\n",
            "4  battle new york primary matters primary day ne...      1\n",
            "label\n",
            "1    3171\n",
            "0    3164\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df[['clean_text', 'label']].head())\n",
        "print(df['label'].value_counts())  # Check balance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b5ccd96",
      "metadata": {
        "id": "4b5ccd96"
      },
      "outputs": [],
      "source": [
        "#Train a baseline model using TF-IDF + Logistic Regression\n",
        "#Train-Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['clean_text']\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acc42fc1",
      "metadata": {
        "id": "acc42fc1"
      },
      "outputs": [],
      "source": [
        "#TF-IDF Vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc8c8cd3",
      "metadata": {
        "id": "bc8c8cd3"
      },
      "outputs": [],
      "source": [
        "#Train a Classifier (Logistic Regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26528b23",
      "metadata": {
        "id": "26528b23",
        "outputId": "9199a77e-53cb-491a-ce1e-17659f41cc8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9194948697711128\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       633\n",
            "           1       0.94      0.90      0.92       634\n",
            "\n",
            "    accuracy                           0.92      1267\n",
            "   macro avg       0.92      0.92      0.92      1267\n",
            "weighted avg       0.92      0.92      0.92      1267\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1d0b8fb",
      "metadata": {
        "id": "b1d0b8fb",
        "outputId": "1a7d7673-f9cd-4a8f-ce80-d2529e8dac69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔴 Top 'FAKE' indicators:\n",
            "fox: 2.0629\n",
            "islamic: 2.1180\n",
            "state: 2.1211\n",
            "debate: 2.2950\n",
            "president: 2.3083\n",
            "sanders: 2.4135\n",
            "candidates: 2.5277\n",
            "cruz: 2.6956\n",
            "gop: 2.7550\n",
            "said: 6.5626\n",
            "\n",
            "🟢 Top 'REAL' indicators:\n",
            "october: -4.5693\n",
            "hillary: -3.8679\n",
            "election: -2.8209\n",
            "november: -2.8071\n",
            "article: -2.4623\n",
            "share: -2.4381\n",
            "source: -2.2480\n",
            "fbi: -2.2260\n",
            "russia: -2.2145\n",
            "wikileaks: -1.9598\n"
          ]
        }
      ],
      "source": [
        "## Get top contributing words\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "coefficients = model.coef_[0]\n",
        "\n",
        "top_fake = np.argsort(coefficients)[-10:]\n",
        "top_real = np.argsort(coefficients)[:10]\n",
        "\n",
        "print(\"🔴 Top 'FAKE' indicators:\")\n",
        "for i in top_fake:\n",
        "    print(f\"{feature_names[i]}: {coefficients[i]:.4f}\")\n",
        "\n",
        "print(\"\\n🟢 Top 'REAL' indicators:\")\n",
        "for i in top_real:\n",
        "    print(f\"{feature_names[i]}: {coefficients[i]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cfcf17f",
      "metadata": {
        "id": "9cfcf17f"
      },
      "outputs": [],
      "source": [
        "#Create a Prediction + Explanation Function\n",
        "import numpy as np\n",
        "\n",
        "def explain_prediction(text, model, vectorizer, top_n=10):\n",
        "    # Vectorize the input text\n",
        "    vec = vectorizer.transform([text])\n",
        "    prediction = model.predict(vec)[0]\n",
        "    proba = model.predict_proba(vec)[0]\n",
        "\n",
        "    # Get feature importance\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    coefs = model.coef_[0]\n",
        "\n",
        "    # Multiply TF-IDF weights by model coefficients\n",
        "    scores = vec.toarray()[0] * coefs\n",
        "    word_score_pairs = [\n",
        "        (feature_names[i], scores[i])\n",
        "        for i in range(len(scores)) if scores[i] != 0\n",
        "    ]\n",
        "\n",
        "    word_score_pairs.sort(key=lambda x: abs(x[1]), reverse=True)\n",
        "    top_words = word_score_pairs[:top_n]\n",
        "\n",
        "    return {\n",
        "        'prediction': prediction,\n",
        "        'confidence': round(np.max(proba), 2),\n",
        "        'top_words': top_words\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f559c34f",
      "metadata": {
        "id": "f559c34f",
        "outputId": "03ce4840-15f1-41c0-a1a0-2c52475953bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: 0 (99.00%)\n",
            "Top Influential Words:\n",
            "hillary: -1.2322\n",
            "fbi: -1.1663\n",
            "investigation: -0.4663\n",
            "elections: -0.3324\n",
            "clinton: 0.0909\n"
          ]
        }
      ],
      "source": [
        "sample_text = \"Hillary Clinton was under FBI investigation during the elections.\"\n",
        "result = explain_prediction(sample_text, model, tfidf)\n",
        "\n",
        "print(f\"Prediction: {result['prediction']} ({result['confidence'] * 100:.2f}%)\")\n",
        "print(\"Top Influential Words:\")\n",
        "for word, score in result['top_words']:\n",
        "    print(f\"{word}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dynamic Misinformation Narrative Tracking & Visualization"
      ],
      "metadata": {
        "id": "2iFqi-F6l5qw"
      },
      "id": "2iFqi-F6l5qw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install all required libraries\n",
        "!pip install pandas numpy spacy scikit-learn plotly pyvis \\\n",
        "            sentence-transformers yake networkx \\\n",
        "            transformers shap matplotlib\n",
        "\n",
        "# Download spaCy English model\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "id": "UMm3JB_Hl5WD",
        "outputId": "b2fc475e-f0e9-4417-8dfb-9a6240c460ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UMm3JB_Hl5WD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Collecting pyvis\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting yake\n",
            "  Downloading yake-0.4.8-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.2)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis) (4.1.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from yake) (0.9.0)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.11/dist-packages (from yake) (8.2.1)\n",
            "Collecting segtok (from yake)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting jellyfish (from yake)\n",
            "  Downloading jellyfish-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}